"""
Convert Keras Model to TensorFlow Lite for ESP32
Generates both .tflite file and C header for Arduino
"""

import tensorflow as tf
import numpy as np
import os
import subprocess

MODEL_DIR = os.path.dirname(__file__)
KERAS_MODEL_PATH = os.path.join(MODEL_DIR, 'fuel_model.h5')
TFLITE_MODEL_PATH = os.path.join(MODEL_DIR, 'fuel_model.tflite')
ESP32_HEADER_PATH = os.path.join(MODEL_DIR, '..', 'esp32', 'fuel_detector', 'model_data.h')

def convert_to_tflite():
    """Convert Keras model to TensorFlow Lite with quantization"""
    print("Loading Keras model...")
    model = tf.keras.models.load_model(KERAS_MODEL_PATH)
    
    print("Converting to TensorFlow Lite...")
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    
    # Optimize for size and speed on microcontrollers
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float16]
    
    tflite_model = converter.convert()
    
    # Save .tflite file
    with open(TFLITE_MODEL_PATH, 'wb') as f:
        f.write(tflite_model)
    
    model_size = len(tflite_model)
    print(f"✅ TFLite model saved to: {TFLITE_MODEL_PATH}")
    print(f"   Model size: {model_size} bytes ({model_size/1024:.2f} KB)")
    
    return tflite_model

def verify_tflite_model(tflite_model):
    """Verify the TFLite model works correctly"""
    print("\nVerifying TFLite model...")
    
    # Load TFLite model
    interpreter = tf.lite.Interpreter(model_content=tflite_model)
    interpreter.allocate_tensors()
    
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    print(f"   Input shape: {input_details[0]['shape']}")
    print(f"   Output shape: {output_details[0]['shape']}")
    
    # Test with sample data
    # Pure petrol: low dielectric (~1.9), high velocity (~1300), low conductivity (~0.3)
    # After scaling (approx): [0, 0, 0]
    test_pure = np.array([[0.0, 0.0, 0.0]], dtype=np.float32)
    
    # Adulterated: higher dielectric, different velocity, higher conductivity
    # After scaling (approx): [2.0, -1.5, 3.0]
    test_adulterated = np.array([[2.0, -1.5, 3.0]], dtype=np.float32)
    
    # Test pure sample
    interpreter.set_tensor(input_details[0]['index'], test_pure)
    interpreter.invoke()
    pure_result = interpreter.get_tensor(output_details[0]['index'])[0][0]
    
    # Test adulterated sample
    interpreter.set_tensor(input_details[0]['index'], test_adulterated)
    interpreter.invoke()
    adulterated_result = interpreter.get_tensor(output_details[0]['index'])[0][0]
    
    print(f"\n   Test Results:")
    print(f"   Pure sample prediction: {pure_result:.4f} (should be < 0.5)")
    print(f"   Adulterated sample prediction: {adulterated_result:.4f} (should be > 0.5)")
    
    if pure_result < 0.5 and adulterated_result > 0.5:
        print("   ✅ Model verification PASSED!")
        return True
    else:
        print("   ⚠️ Model verification needs checking")
        return False

def generate_c_header(tflite_model):
    """Generate C header file for Arduino/ESP32"""
    print("\nGenerating C header for ESP32...")
    
    # Convert to C array
    hex_array = ', '.join([f'0x{b:02x}' for b in tflite_model])
    
    header_content = f'''// Auto-generated model data for ESP32
// Model: Fuel Quality Detection (Binary Classification)
// Generated by convert_to_tflite.py

#ifndef MODEL_DATA_H
#define MODEL_DATA_H

const unsigned char fuel_model_tflite[] = {{
  {hex_array}
}};

const unsigned int fuel_model_tflite_len = {len(tflite_model)};

// Scaler parameters for input normalization
// These values should match the scaler used during training
'''
    
    # Read scaler params if available
    scaler_params_path = os.path.join(MODEL_DIR, 'scaler_params.txt')
    if os.path.exists(scaler_params_path):
        with open(scaler_params_path, 'r') as f:
            lines = f.readlines()
            for line in lines:
                if line.startswith('MEAN'):
                    mean_vals = line.split('=')[1].strip().strip('[]').split(',')
                    header_content += f"const float SCALER_MEAN[3] = {{{mean_vals[0]}, {mean_vals[1]}, {mean_vals[2]}}};\n"
                elif line.startswith('STD'):
                    std_vals = line.split('=')[1].strip().strip('[]').split(',')
                    header_content += f"const float SCALER_STD[3] = {{{std_vals[0]}, {std_vals[1]}, {std_vals[2]}}};\n"
    
    header_content += "\n#endif // MODEL_DATA_H\n"
    
    # Save header file
    os.makedirs(os.path.dirname(ESP32_HEADER_PATH), exist_ok=True)
    with open(ESP32_HEADER_PATH, 'w') as f:
        f.write(header_content)
    
    print(f"✅ C header saved to: {ESP32_HEADER_PATH}")

def main():
    print("=" * 60)
    print("TensorFlow Lite Model Conversion")
    print("=" * 60)
    
    # Check if Keras model exists
    if not os.path.exists(KERAS_MODEL_PATH):
        print(f"❌ Keras model not found at: {KERAS_MODEL_PATH}")
        print("   Please run model_training.py first!")
        return
    
    # Convert
    tflite_model = convert_to_tflite()
    
    # Verify
    verify_tflite_model(tflite_model)
    
    # Generate header
    generate_c_header(tflite_model)
    
    print("\n" + "=" * 60)
    print("Conversion complete!")
    print("Next steps:")
    print("1. Open fuel_detector.ino in Arduino IDE")
    print("2. Install TensorFlowLite_ESP32 library")
    print("3. Upload to ESP32")
    print("=" * 60)

if __name__ == "__main__":
    main()
